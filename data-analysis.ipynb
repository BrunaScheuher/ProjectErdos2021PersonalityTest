{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4aadef29-e824-4eba-ad7e-0a718b2fc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example statement is waitting to be verified: \n",
    "# A person loves saying these words, he/she would be (classidied) to be an INTJ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd5e5ba7-92f9-4975-a546-6d95b5961c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T02:57:25.350546Z",
     "start_time": "2021-05-27T02:57:23.338331Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "372eeec8-ab42-4250-b68c-76b735b8eed3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T04:58:03.021790Z",
     "start_time": "2021-05-27T04:58:03.017550Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "    \n",
    "# from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "daee7dd6-6393-4b8c-8121-df123124468e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T02:57:26.676801Z",
     "start_time": "2021-05-27T02:57:26.647529Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_processed.csv')\n",
    "\n",
    "df_sample = df.copy()\n",
    "\n",
    "type_list = ['INFJ','INFP','INTJ','INTP',\n",
    "             'ENFJ','ENFP','ENTJ','ENTP',\n",
    "             'ISFJ','ISFP','ISTJ','ISTP',\n",
    "             'ESFJ','ESFP','ESTJ','ESTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02930dff-e3f2-4dd3-8659-9e7c417588c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"type\",\"scores\"],axis =1).to_numpy() \n",
    "\n",
    "sum_of_rows = np.sum(X,axis=1)\n",
    "normalized_X = X * 10 / sum_of_rows[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ede44cfb-6bb0-41ab-a2f2-e01f54c589d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d9376c2-6e21-485b-a558-e4e2188e93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: INFJ ; Acc_Score: 0.8243061772605192 ;\n",
      "LogisticRegression: INFP ; Acc_Score: 0.7761862130707251 ;\n",
      "LogisticRegression: INTJ ; Acc_Score: 0.8807072515666965 ;\n",
      "LogisticRegression: INTP ; Acc_Score: 0.8538495971351835 ;\n",
      "LogisticRegression: ENFJ ; Acc_Score: 0.9771709937332139 ;\n",
      "LogisticRegression: ENFP ; Acc_Score: 0.9196508504923904 ;\n",
      "LogisticRegression: ENTJ ; Acc_Score: 0.9742614145031334 ;\n",
      "LogisticRegression: ENTP ; Acc_Score: 0.916965085049239 ;\n",
      "LogisticRegression: ISFJ ; Acc_Score: 0.9823187108325873 ;\n",
      "LogisticRegression: ISFP ; Acc_Score: 0.9693375111906893 ;\n",
      "LogisticRegression: ISTJ ; Acc_Score: 0.9780662488809311 ;\n",
      "LogisticRegression: ISTP ; Acc_Score: 0.9597135183527306 ;\n",
      "LogisticRegression: ESFJ ; Acc_Score: 0.9944046553267681 ;\n",
      "LogisticRegression: ESFP ; Acc_Score: 0.9944046553267681 ;\n",
      "LogisticRegression: ESTJ ; Acc_Score: 0.9950760966875559 ;\n",
      "LogisticRegression: ESTP ; Acc_Score: 0.990152193375112 ;\n",
      "Decision Tree model: INFJ ; 71.02 % accuracy on the test set\n",
      "Decision Tree model: INFP ; 67.89 % accuracy on the test set\n",
      "Decision Tree model: INTJ ; 77.37 % accuracy on the test set\n",
      "Decision Tree model: INTP ; 76.21 % accuracy on the test set\n",
      "Decision Tree model: ENFJ ; 94.54 % accuracy on the test set\n",
      "Decision Tree model: ENFP ; 82.11 % accuracy on the test set\n",
      "Decision Tree model: ENTJ ; 92.93 % accuracy on the test set\n",
      "Decision Tree model: ENTP ; 85.87 % accuracy on the test set\n",
      "Decision Tree model: ISFJ ; 95.08 % accuracy on the test set\n",
      "Decision Tree model: ISFP ; 93.83 % accuracy on the test set\n",
      "Decision Tree model: ISTJ ; 95.17 % accuracy on the test set\n",
      "Decision Tree model: ISTP ; 91.59 % accuracy on the test set\n",
      "Decision Tree model: ESFJ ; 99.02 % accuracy on the test set\n",
      "Decision Tree model: ESFP ; 99.02 % accuracy on the test set\n",
      "Decision Tree model: ESTJ ; 99.02 % accuracy on the test set\n",
      "Decision Tree model: ESTP ; 97.67 % accuracy on the test set\n",
      "K Neighbors model: INFJ ; 82.65 % accuracy on the test set\n",
      "K Neighbors model: INFP ; 79.7 % accuracy on the test set\n",
      "K Neighbors model: INTJ ; 87.12 % accuracy on the test set\n",
      "K Neighbors model: INTP ; 86.31 % accuracy on the test set\n",
      "K Neighbors model: ENFJ ; 97.5 % accuracy on the test set\n",
      "K Neighbors model: ENFP ; 91.06 % accuracy on the test set\n",
      "K Neighbors model: ENTJ ; 97.14 % accuracy on the test set\n",
      "K Neighbors model: ENTP ; 91.14 % accuracy on the test set\n",
      "K Neighbors model: ISFJ ; 98.3 % accuracy on the test set\n",
      "K Neighbors model: ISFP ; 96.96 % accuracy on the test set\n",
      "K Neighbors model: ISTJ ; 97.67 % accuracy on the test set\n",
      "K Neighbors model: ISTP ; 96.06 % accuracy on the test set\n",
      "K Neighbors model: ESFJ ; 99.11 % accuracy on the test set\n",
      "K Neighbors model: ESFP ; 99.37 % accuracy on the test set\n",
      "K Neighbors model: ESTJ ; 99.91 % accuracy on the test set\n",
      "K Neighbors model: ESTP ; 99.19 % accuracy on the test set\n",
      "Extra Tree Classifier: INFJ ; 71.11 % accuracy on the test set\n",
      "Extra Tree Classifier: INFP ; 66.64 % accuracy on the test set\n",
      "Extra Tree Classifier: INTJ ; 79.61 % accuracy on the test set\n",
      "Extra Tree Classifier: INTP ; 74.87 % accuracy on the test set\n",
      "Extra Tree Classifier: ENFJ ; 94.1 % accuracy on the test set\n",
      "Extra Tree Classifier: ENFP ; 84.35 % accuracy on the test set\n",
      "Extra Tree Classifier: ENTJ ; 95.26 % accuracy on the test set\n",
      "Extra Tree Classifier: ENTP ; 86.31 % accuracy on the test set\n",
      "Extra Tree Classifier: ISFJ ; 94.63 % accuracy on the test set\n",
      "Extra Tree Classifier: ISFP ; 94.1 % accuracy on the test set\n",
      "Extra Tree Classifier: ISTJ ; 94.9 % accuracy on the test set\n",
      "Extra Tree Classifier: ISTP ; 91.68 % accuracy on the test set\n",
      "Extra Tree Classifier: ESFJ ; 99.02 % accuracy on the test set\n",
      "Extra Tree Classifier: ESFP ; 99.19 % accuracy on the test set\n",
      "Extra Tree Classifier: ESTJ ; 98.84 % accuracy on the test set\n",
      "Extra Tree Classifier: ESTP ; 96.69 % accuracy on the test set\n"
     ]
    }
   ],
   "source": [
    "type_list = ['INFJ','INFP','INTJ','INTP',\n",
    "             'ENFJ','ENFP','ENTJ','ENTP',\n",
    "             'ISFJ','ISFP','ISTJ','ISTP',\n",
    "             'ESFJ','ESFP','ESTJ','ESTP']\n",
    "\n",
    "for idx in range(0,16):\n",
    "    df_sample.loc[df['type'] == type_list[idx], 'dummy'] = 1\n",
    "    df_sample.loc[df['type'] != type_list[idx], 'dummy'] = 0\n",
    "    \n",
    "    Y = df_sample[['dummy']].to_numpy()\n",
    "    encoder_y=LabelEncoder()\n",
    "    normalized_Y = encoder_y.fit_transform(Y.ravel())\n",
    "    \n",
    "    X_train, X_test, Y_train ,Y_test = train_test_split(normalized_X, normalized_Y, test_size=0.2)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"LogisticRegression:\",type_list[idx],\";\",\n",
    "#          \"Predict:\",clf.predict(X_test),\";\",\n",
    "          \"Acc_Score:\",clf.score(X_train,Y_train),\";\",\n",
    "#          \"Pred_Proba:\",clf.predict_proba(X_test)\n",
    "         )\n",
    "\n",
    "for idx in range(0,16):\n",
    "    df_sample.loc[df['type'] == type_list[idx], 'dummy'] = 1\n",
    "    df_sample.loc[df['type'] != type_list[idx], 'dummy'] = 0\n",
    "    \n",
    "    Y = df_sample[['dummy']].to_numpy()\n",
    "    encoder_y=LabelEncoder()\n",
    "    normalized_Y = encoder_y.fit_transform(Y.ravel())\n",
    "    \n",
    "    X_train, X_test, Y_train ,Y_test = train_test_split(normalized_X, normalized_Y, test_size=0.2)\n",
    "    \n",
    "    cls = DecisionTreeClassifier()\n",
    "    cls.fit(X_train, Y_train)\n",
    "    Y_pred = cls.predict(X_test)\n",
    "    print(\"Decision Tree model:\",type_list[idx],\";\",\n",
    "      np.round(sum(Y_pred == Y_test.ravel())/len(Y_test.ravel())*100,2),\n",
    "      \"% accuracy on the test set\")\n",
    "    \n",
    "for idx in range(0,16):\n",
    "    df_sample.loc[df['type'] == type_list[idx], 'dummy'] = 1\n",
    "    df_sample.loc[df['type'] != type_list[idx], 'dummy'] = 0\n",
    "    \n",
    "    Y = df_sample[['dummy']].to_numpy()\n",
    "    encoder_y=LabelEncoder()\n",
    "    normalized_Y = encoder_y.fit_transform(Y.ravel())\n",
    "    \n",
    "    X_train, X_test, Y_train ,Y_test = train_test_split(normalized_X, normalized_Y, test_size=0.2)\n",
    "        \n",
    "    cls = KNeighborsClassifier(n_neighbors = 600)\n",
    "    cls.fit(X_train, Y_train)\n",
    "    Y_pred = cls.predict(X_test)\n",
    "    print(\"K Neighbors model:\",type_list[idx],\";\",\n",
    "          np.round(sum(Y_pred == Y_test.ravel())/len(Y_test.ravel())*100,2),\n",
    "          \"% accuracy on the test set\")\n",
    "    \n",
    "for idx in range(0,16):\n",
    "    df_sample.loc[df['type'] == type_list[idx], 'dummy'] = 1\n",
    "    df_sample.loc[df['type'] != type_list[idx], 'dummy'] = 0\n",
    "    \n",
    "    Y = df_sample[['dummy']].to_numpy()\n",
    "    encoder_y=LabelEncoder()\n",
    "    normalized_Y = encoder_y.fit_transform(Y.ravel())\n",
    "    \n",
    "    X_train, X_test, Y_train ,Y_test = train_test_split(normalized_X, normalized_Y, test_size=0.2)\n",
    "\n",
    "    cls = sklearn.tree.ExtraTreeClassifier()\n",
    "    cls.fit(X_train, Y_train)\n",
    "    Y_pred = cls.predict(X_test)\n",
    "    print(\"Extra Tree Classifier:\",type_list[idx],\";\",\n",
    "      np.round(sum(Y_pred == Y_test.ravel())/len(Y_test.ravel())*100,2),\n",
    "      \"% accuracy on the test set\")\n",
    "\n",
    "#    cls = RandomForestClassifier()\n",
    "#    cls.fit(X_train, Y_train)\n",
    "#    Y_pred = cls.predict(X_test)\n",
    "#    print(\"Random Forest Classifier model has a \",\n",
    "#        np.round(sum(Y_pred == Y_test.ravel())/len(Y_test.ravel())*100,2),\n",
    "#          \"% accuracy on the test set\")\n",
    "\n",
    "#    cls = RidgeClassifierCV()\n",
    "#    cls.fit(X_train, Y_train)\n",
    "#    Y_pred = cls.predict(X_test)\n",
    "#    print(\"Ridge Classifier model has a \",\n",
    "#         np.round(sum(Y_pred == Y_test.ravel())/len(Y_test.ravel())*100,2),\n",
    "#          \"% accuracy on the test set\")\n",
    "\n",
    "#    cls = MLPClassifier(max_iter = 800) # very slow\n",
    "#    cls.fit(X_train, Y_train)\n",
    "#    Y_pred = cls.predict(X_test)\n",
    "#    print(\"MLP Classifier model has a \",\n",
    "#       np.round(sum(Y_pred == Y_test.ravel())/len(Y_test.ravel())*100,2),\n",
    "#       \"% accuracy on the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "180978a6-33d1-4fbb-8769-42e77143d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression_ haven't known yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fbb1f171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T05:47:04.264276Z",
     "start_time": "2021-05-27T05:47:04.255599Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data Preperation for regression model\n",
    "X = df.drop([\"type\",\"scores\"],axis =1).to_numpy()\n",
    "Y = df[\"scores\"]\n",
    "\n",
    "sum_of_rows = np.sum(X,axis=1)\n",
    "normalized_X = X * 10 / sum_of_rows[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "caf0fd4e-acba-4f01-b77b-0f5187405686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>dont</th>\n",
       "      <th>feel</th>\n",
       "      <th>love</th>\n",
       "      <th>much</th>\n",
       "      <th>well</th>\n",
       "      <th>say</th>\n",
       "      <th>good</th>\n",
       "      <th>something</th>\n",
       "      <th>things</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>lot</th>\n",
       "      <th>though</th>\n",
       "      <th>thats</th>\n",
       "      <th>make</th>\n",
       "      <th>never</th>\n",
       "      <th>go</th>\n",
       "      <th>always</th>\n",
       "      <th>even</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.443125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.443125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.443125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.443125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.443125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5581</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.435104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.435104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.435104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.435104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.435104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5586 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  dont  feel  love  much  well   say  good  something  things  ...  \\\n",
       "0     INFJ  14.0   9.0   7.0   3.0   5.0   5.0  11.0        2.0     3.0  ...   \n",
       "1     INFJ  11.0   7.0   2.0   4.0   0.0   4.0   3.0        3.0     5.0  ...   \n",
       "2     INFJ  13.0   7.0   2.0   7.0   1.0   4.0   3.0        2.0     2.0  ...   \n",
       "3     INFJ   4.0   9.0   5.0   7.0   4.0   4.0   6.0        1.0     1.0  ...   \n",
       "4     INFJ  10.0   7.0  10.0   5.0   2.0   5.0   2.0        2.0     1.0  ...   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...        ...     ...  ...   \n",
       "5581  ESTP  11.0   2.0   6.0   1.0   4.0   4.0   2.0        2.0     4.0  ...   \n",
       "5582  ESTP  15.0   4.0   3.0   5.0  12.0   8.0   3.0        5.0     4.0  ...   \n",
       "5583  ESTP  10.0   7.0   1.0   5.0   9.0  10.0   6.0        1.0     2.0  ...   \n",
       "5584  ESTP   9.0   3.0   1.0   5.0   6.0   6.0   6.0        3.0     2.0  ...   \n",
       "5585  ESTP  13.0   3.0   6.0   2.0   3.0   9.0   4.0        4.0     2.0  ...   \n",
       "\n",
       "      youre  lot  though  thats  make  never    go  always  even    scores  \n",
       "0       3.0  2.0     7.0    2.0   2.0    3.0  18.0     3.0   3.0  1.443125  \n",
       "1       6.0  3.0     7.0    3.0   5.0    1.0  19.0     4.0   5.0  1.443125  \n",
       "2       6.0  3.0     5.0    3.0   8.0    7.0  17.0     3.0   3.0  1.443125  \n",
       "3       0.0  3.0     7.0    2.0   4.0    2.0  22.0     4.0   0.0  1.443125  \n",
       "4       2.0  5.0     3.0    1.0   4.0    5.0  11.0    10.0   6.0  1.443125  \n",
       "...     ...  ...     ...    ...   ...    ...   ...     ...   ...       ...  \n",
       "5581    4.0  2.0     3.0    5.0   7.0    2.0  14.0     3.0   4.0  1.435104  \n",
       "5582    4.0  3.0     1.0    4.0   5.0    4.0  16.0     8.0   2.0  1.435104  \n",
       "5583    0.0  4.0     6.0    2.0   7.0    2.0  13.0     5.0   7.0  1.435104  \n",
       "5584    1.0  3.0    10.0    2.0   4.0    2.0  25.0     3.0   3.0  1.435104  \n",
       "5585    5.0  5.0     4.0    1.0   0.0    5.0   9.0     4.0   3.0  1.435104  \n",
       "\n",
       "[5586 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bd8b94f-256e-4f77-906d-4fafd5942a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR has a  -0.010205704059609744 R2 on the test set\n",
      "SVR has a  0.019336271914466963 R2 on the test set\n",
      "SVR has a  0.010653577283858628 R2 on the test set\n",
      "SVR has a  0.00849086311435443 R2 on the test set\n",
      "SVR has a  0.011988128394366915 R2 on the test set\n",
      "SVR has a  0.019090687072662815 R2 on the test set\n",
      "SVR has a  -0.016051680660356782 R2 on the test set\n",
      "SVR has a  0.006292648596780692 R2 on the test set\n",
      "SVR has a  0.012796808576411078 R2 on the test set\n",
      "SVR has a  0.016170340508282366 R2 on the test set\n",
      "SVR has a  -0.001098891279186942 R2 on the test set\n",
      "SVR has a  0.01615776899998045 R2 on the test set\n",
      "SVR has a  0.00612372888460222 R2 on the test set\n",
      "SVR has a  0.02216524369941897 R2 on the test set\n",
      "SVR has a  0.008087379702475306 R2 on the test set\n",
      "SVR has a  0.01581205127389107 R2 on the test set\n"
     ]
    }
   ],
   "source": [
    "type_list = ['INFJ','INFP','INTJ','INTP',\n",
    "             'ENFJ','ENFP','ENTJ','ENTP',\n",
    "             'ISFJ','ISFP','ISTJ','ISTP',\n",
    "             'ESFJ','ESFP','ESTJ','ESTP']\n",
    "\n",
    "for idx in range(0,16):\n",
    "    df_sample.loc[df['type'] == type_list[idx], 'dummy'] = 1\n",
    "    df_sample.loc[df['type'] != type_list[idx], 'dummy'] = 0\n",
    "    \n",
    "    Y = df_sample[['scores']].to_numpy()\n",
    "    encoder_y=LabelEncoder()\n",
    "    normalized_Y = encoder_y.fit_transform(Y.ravel())\n",
    "    \n",
    "    X_train, X_test, Y_train ,Y_test = train_test_split(normalized_X, normalized_Y, test_size=0.2)\n",
    "    \n",
    "    cls = svm.SVR()\n",
    "    cls.fit(X_train, Y_train)\n",
    "    print(\"SVR has a \",\n",
    "         cls.score(X_test, Y_test),\n",
    "         \"R2 on the test set\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "769fd9c3-2793-4ee5-bdf1-aee2e81638de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The question, we are trying to answer:\n",
    "# An INTJ person would like to say what words? What words are very common if we know she/he is an INTJ person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99d5efeb-db6a-4270-8183-e687890d0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"raw_data.csv\")\n",
    "df_stop_words = pd.read_csv(\"stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41f82bc6-e8d7-4e85-8f7b-9e1a659bfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw\n",
    "stop_words = df_stop_words['excluded_words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44aeb597-3e38-410a-be5f-316f10397a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ISTP</th>\n",
       "      <th>idposts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what has been the most lifechanging experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>on repeat for most of today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>may the perc experience immerse you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the last thing my infj friend posted on his fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENFJ  ENFP  ENTJ  ENTP  ESFJ  ESFP  ESTJ  ESTP  INFJ  INFP  INTJ  INTP  \\\n",
       "0     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "3     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "4     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "\n",
       "   ISFJ  ISFP  ISTJ  ISTP                                            idposts  \n",
       "0     0     0     0     0  enfp and intj moments    sportscenter not top ...  \n",
       "1     0     0     0     0  what has been the most lifechanging experience...  \n",
       "2     0     0     0     0                        on repeat for most of today  \n",
       "3     0     0     0     0                may the perc experience immerse you  \n",
       "4     0     0     0     0  the last thing my infj friend posted on his fa...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding the type\n",
    "df_prepare = pd.get_dummies(df_raw.type)\n",
    "df_prepare['idposts'] = df_raw.idposts\n",
    "df_prepare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68be3c0c-08a4-4b33-8deb-55f346e55e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274990,)\n",
      "(135444,)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df_prepare, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train.idposts\n",
    "X_test = test.idposts\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "016f4e4a-448e-44d6-b035-bbd98ce4c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing INFJ\n",
      "... Processing INFP\n",
      "... Processing INTJ\n",
      "... Processing INTP\n",
      "... Processing ENFJ\n",
      "... Processing ENFP\n",
      "... Processing ENTJ\n",
      "... Processing ENTP\n",
      "... Processing ISFJ\n",
      "... Processing ISFP\n",
      "... Processing ISTJ\n",
      "... Processing ISTP\n",
      "... Processing ESFJ\n",
      "... Processing ESFP\n",
      "... Processing ESTJ\n",
      "... Processing ESTP\n",
      "Test accuracy for LinearSVC 0.9894790466908833\n"
     ]
    }
   ],
   "source": [
    "CLF_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf',OneVsRestClassifier(LinearSVC(random_state=640)))\n",
    "#                ('clf',OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)))\n",
    "            ])\n",
    "for category in type_list:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # Use X_train and y to fit the model\n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    # Calculate the prediction\n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "print('Test accuracy for LinearSVC {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "47084347-493a-4cb6-aafe-a09b9bc8f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a part of of the group project, no distributed. xiaoyuwang421@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45f9b4-50fb-4be9-9020-417342ad948e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
